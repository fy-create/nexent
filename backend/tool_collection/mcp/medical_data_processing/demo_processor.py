"""
åŒ»ç–—æ•°æ®å·¥ç¨‹æ¼”ç¤ºå¤„ç†å™¨
å±•ç¤ºå®Œæ•´çš„åŒ»ç–—æ•°æ®å¤„ç†æµç¨‹ï¼šæ•°æ®æ¸…æ´— â†’ ä¸“ä¸šæ ‡æ³¨ â†’ Q&Aç”Ÿæˆ â†’ çŸ¥è¯†åº“é›†æˆ
"""

import logging
from typing import Dict, List, Any, Optional
import json
from datetime import datetime
import os

from .data_cleaner import MedicalDataCleaner
from .professional_annotator import MedicalProfessionalAnnotator
from .qa_generator import MedicalQAGenerator
from .knowledge_base_integrator import MedicalKnowledgeBaseIntegrator

logger = logging.getLogger(__name__)

class MedicalDataEngineeringDemo:
    """åŒ»ç–—æ•°æ®å·¥ç¨‹æ¼”ç¤ºå¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤ºå¤„ç†å™¨"""
        self.cleaner = MedicalDataCleaner()
        self.annotator = MedicalProfessionalAnnotator()
        self.generator = MedicalQAGenerator()
        self.integrator = MedicalKnowledgeBaseIntegrator()
        
        # æ¼”ç¤ºç”¨çš„ç—…ç†æ•™ç§‘ä¹¦æ ·æœ¬æ•°æ®
        self.sample_pathology_text = """
        è‚ºç™Œæ˜¯æœ€å¸¸è§çš„æ¶æ€§è‚¿ç˜¤ä¹‹ä¸€ï¼Œæ ¹æ®ç»„ç»‡å­¦ç‰¹å¾å¯åˆ†ä¸ºå°ç»†èƒè‚ºç™Œå’Œéå°ç»†èƒè‚ºç™Œã€‚
        
        éå°ç»†èƒè‚ºç™ŒåŒ…æ‹¬è…ºç™Œã€é³çŠ¶ç»†èƒç™Œå’Œå¤§ç»†èƒç™Œã€‚è…ºç™Œæ˜¯æœ€å¸¸è§çš„è‚ºç™Œç±»å‹ï¼Œ
        å¸¸è§äºå¥³æ€§å’Œéå¸çƒŸè€…ã€‚é•œä¸‹å¯è§è…ºä½“ç»“æ„ï¼Œç»†èƒå¼‚å‹æ€§æ˜æ˜¾ï¼Œæ ¸åˆ†è£‚è±¡å¢å¤šã€‚
        
        ä¸´åºŠè¡¨ç°åŒ…æ‹¬å’³å—½ã€å’³ç—°ã€èƒ¸ç—›ã€å‘¼å¸å›°éš¾ç­‰ç—‡çŠ¶ã€‚æ—©æœŸè‚ºç™Œç—‡çŠ¶ä¸æ˜æ˜¾ï¼Œ
        å¤šæ•°æ‚£è€…ç¡®è¯Šæ—¶å·²ä¸ºä¸­æ™šæœŸã€‚
        
        è¯Šæ–­æ–¹æ³•åŒ…æ‹¬èƒ¸éƒ¨CTã€æ”¯æ°”ç®¡é•œæ£€æŸ¥ã€ç—°ç»†èƒå­¦æ£€æŸ¥å’Œç»„ç»‡ç—…ç†å­¦æ£€æŸ¥ã€‚
        ç»„ç»‡ç—…ç†å­¦æ£€æŸ¥æ˜¯ç¡®è¯Šçš„é‡‘æ ‡å‡†ã€‚
        
        æ²»ç–—æ–¹æ¡ˆæ ¹æ®ç—…ç†ç±»å‹ã€åˆ†æœŸå’Œæ‚£è€…ä¸€èˆ¬çŠ¶å†µåˆ¶å®šï¼ŒåŒ…æ‹¬æ‰‹æœ¯æ²»ç–—ã€
        æ”¾å°„æ²»ç–—ã€åŒ–å­¦æ²»ç–—å’Œé¶å‘æ²»ç–—ç­‰ã€‚æ—©æœŸè‚ºç™Œé¦–é€‰æ‰‹æœ¯æ²»ç–—ï¼Œ
        æ™šæœŸè‚ºç™Œä»¥åŒ–ç–—å’Œé¶å‘æ²»ç–—ä¸ºä¸»ã€‚
        
        é¢„åä¸ç—…ç†ç±»å‹ã€åˆ†æœŸã€æ²»ç–—æ–¹æ¡ˆç­‰å› ç´ ç›¸å…³ã€‚æ—©æœŸå‘ç°å’Œè§„èŒƒæ²»ç–—
        å¯æ˜¾è‘—æ”¹å–„æ‚£è€…é¢„åã€‚
        """
    
    def run_complete_demo(self, input_text: str = None, 
                         qa_count: int = 8,
                         create_knowledge_base: bool = True) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„åŒ»ç–—æ•°æ®å·¥ç¨‹æ¼”ç¤º
        
        Args:
            input_text: è¾“å…¥çš„åŒ»ç–—æ–‡æœ¬ï¼Œé»˜è®¤ä½¿ç”¨æ ·æœ¬æ•°æ®
            qa_count: ç”Ÿæˆçš„Q&Aå¯¹æ•°é‡
            create_knowledge_base: æ˜¯å¦åˆ›å»ºçŸ¥è¯†åº“å¹¶å­˜å‚¨æ•°æ®
            
        Returns:
            å®Œæ•´çš„æ¼”ç¤ºç»“æœ
        """
        demo_result = {
            "demo_info": {
                "title": "åŒ»ç–—æ•°æ®å·¥ç¨‹ä¸æ¨¡å‹è®­ç»ƒæ¼”ç¤º",
                "description": "å±•ç¤ºç—…ç†æ•™ç§‘ä¹¦æ•°æ®å¤„ç†çš„å®Œæ•´æµç¨‹",
                "start_time": datetime.now().isoformat(),
                "input_text_length": 0,
                "qa_target_count": qa_count,
                "knowledge_base_integration": create_knowledge_base
            },
            "processing_steps": [],
            "final_results": {},
            "performance_metrics": {}
        }
        
        try:
            # ä½¿ç”¨è¾“å…¥æ–‡æœ¬æˆ–æ ·æœ¬æ•°æ®
            text_to_process = input_text if input_text else self.sample_pathology_text
            demo_result["demo_info"]["input_text_length"] = len(text_to_process)
            
            # æ­¥éª¤1: æ•°æ®æ¸…æ´—
            print("ğŸ”„ æ­¥éª¤1: åŒ»ç–—æ•°æ®æ¸…æ´—...")
            cleaning_start = datetime.now()
            
            cleaning_result = self.cleaner.clean_medical_text(text_to_process)
            
            cleaning_step = {
                "step_number": 1,
                "step_name": "åŒ»ç–—æ•°æ®æ¸…æ´—",
                "status": "completed" if cleaning_result.get("success") else "failed",
                "processing_time": (datetime.now() - cleaning_start).total_seconds(),
                "input_length": len(text_to_process),
                "output_length": len(cleaning_result.get("cleaned_text", "")),
                "quality_score": cleaning_result.get("quality_score", 0),
                "medical_terms_extracted": len(cleaning_result.get("medical_terms", {})),
                "segments_created": len(cleaning_result.get("segments", []))
            }
            demo_result["processing_steps"].append(cleaning_step)
            
            if not cleaning_result.get("success"):
                raise Exception("æ•°æ®æ¸…æ´—æ­¥éª¤å¤±è´¥")
            
            # æ­¥éª¤2: ä¸“ä¸šæ ‡æ³¨
            print("ğŸ”„ æ­¥éª¤2: åŒ»ç–—ä¸“ä¸šæ ‡æ³¨...")
            annotation_start = datetime.now()
            
            cleaned_text = cleaning_result.get("cleaned_text", "")
            annotation_result = self.annotator.annotate_medical_content(cleaned_text, "pathology")
            
            annotation_step = {
                "step_number": 2,
                "step_name": "åŒ»ç–—ä¸“ä¸šæ ‡æ³¨",
                "status": "completed" if annotation_result.get("success") else "failed",
                "processing_time": (datetime.now() - annotation_start).total_seconds(),
                "pathology_annotations": len(annotation_result.get("annotations", {}).get("pathology", {})),
                "diagnosis_annotations": len(annotation_result.get("annotations", {}).get("diagnosis", {})),
                "key_entities": len(annotation_result.get("annotations", {}).get("entities", [])),
                "relationships": len(annotation_result.get("annotations", {}).get("relationships", []))
            }
            demo_result["processing_steps"].append(annotation_step)
            
            if not annotation_result.get("success"):
                raise Exception("ä¸“ä¸šæ ‡æ³¨æ­¥éª¤å¤±è´¥")
            
            # æ­¥éª¤3: Q&Aç”Ÿæˆ
            print("ğŸ”„ æ­¥éª¤3: åŒ»ç–—Q&Aæ•°æ®é›†ç”Ÿæˆ...")
            qa_start = datetime.now()
            
            qa_result = self.generator.generate_qa_dataset(annotation_result, qa_count)
            
            qa_step = {
                "step_number": 3,
                "step_name": "åŒ»ç–—Q&Aæ•°æ®é›†ç”Ÿæˆ",
                "status": "completed" if qa_result.get("success") else "failed",
                "processing_time": (datetime.now() - qa_start).total_seconds(),
                "target_qa_count": qa_count,
                "actual_qa_count": len(qa_result.get("qa_pairs", [])),
                "average_quality": qa_result.get("quality_metrics", {}).get("overall_quality", 0),
                "difficulty_distribution": qa_result.get("quality_metrics", {}).get("difficulty_distribution", {})
            }
            demo_result["processing_steps"].append(qa_step)
            
            if not qa_result.get("success"):
                raise Exception("Q&Aç”Ÿæˆæ­¥éª¤å¤±è´¥")
            
            # æ­¥éª¤4: çŸ¥è¯†åº“é›†æˆï¼ˆå¯é€‰ï¼‰
            knowledge_base_result = None
            if create_knowledge_base:
                print("ğŸ”„ æ­¥éª¤4: çŸ¥è¯†åº“é›†æˆ...")
                kb_start = datetime.now()
                
                # åˆ›å»ºåŒ»ç–—çŸ¥è¯†åº“ç´¢å¼•
                index_creation = self.integrator.create_medical_knowledge_index()
                
                if index_creation.get("success"):
                    index_name = index_creation.get("index_name")
                    
                    # é›†æˆQ&Aæ•°æ®åˆ°çŸ¥è¯†åº“
                    qa_pairs = qa_result.get("qa_pairs", [])
                    integration_result = self.integrator.integrate_qa_dataset(qa_pairs, index_name)
                    
                    knowledge_base_result = {
                        "index_creation": index_creation,
                        "data_integration": integration_result
                    }
                    
                    kb_step = {
                        "step_number": 4,
                        "step_name": "çŸ¥è¯†åº“é›†æˆ",
                        "status": "completed" if integration_result.get("success") else "failed",
                        "processing_time": (datetime.now() - kb_start).total_seconds(),
                        "index_name": index_name,
                        "documents_indexed": integration_result.get("total_indexed", 0),
                        "index_stats": integration_result.get("index_stats", {})
                    }
                    demo_result["processing_steps"].append(kb_step)
                else:
                    kb_step = {
                        "step_number": 4,
                        "step_name": "çŸ¥è¯†åº“é›†æˆ",
                        "status": "failed",
                        "processing_time": (datetime.now() - kb_start).total_seconds(),
                        "error": index_creation.get("error", "ç´¢å¼•åˆ›å»ºå¤±è´¥")
                    }
                    demo_result["processing_steps"].append(kb_step)
            
            # æ±‡æ€»æœ€ç»ˆç»“æœ
            demo_result["final_results"] = {
                "data_cleaning": {
                    "original_length": len(text_to_process),
                    "cleaned_length": len(cleaned_text),
                    "quality_score": cleaning_result.get("quality_score", 0),
                    "medical_terms": cleaning_result.get("medical_terms", {}),
                    "segments_count": len(cleaning_result.get("segments", []))
                },
                "professional_annotation": {
                    "annotation_categories": list(annotation_result.get("annotations", {}).keys()),
                    "total_entities": len(annotation_result.get("annotations", {}).get("entities", [])),
                    "total_relationships": len(annotation_result.get("annotations", {}).get("relationships", []))
                },
                "qa_generation": {
                    "total_qa_pairs": len(qa_result.get("qa_pairs", [])),
                    "quality_metrics": qa_result.get("quality_metrics", {}),
                    "sample_qa_pairs": qa_result.get("qa_pairs", [])[:3]  # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
                },
                "knowledge_base": knowledge_base_result if knowledge_base_result else {"status": "skipped"}
            }
            
            # æ€§èƒ½æŒ‡æ ‡
            total_time = (datetime.now() - datetime.fromisoformat(demo_result["demo_info"]["start_time"])).total_seconds()
            demo_result["performance_metrics"] = {
                "total_processing_time": total_time,
                "steps_completed": len([s for s in demo_result["processing_steps"] if s["status"] == "completed"]),
                "steps_failed": len([s for s in demo_result["processing_steps"] if s["status"] == "failed"]),
                "success_rate": len([s for s in demo_result["processing_steps"] if s["status"] == "completed"]) / len(demo_result["processing_steps"]),
                "data_quality_improvement": cleaning_result.get("quality_score", 0),
                "knowledge_extraction_efficiency": len(qa_result.get("qa_pairs", [])) / len(text_to_process) * 1000  # æ¯åƒå­—ç¬¦ç”Ÿæˆçš„Q&Aå¯¹æ•°
            }
            
            demo_result["demo_info"]["end_time"] = datetime.now().isoformat()
            demo_result["demo_info"]["status"] = "completed"
            
            print("âœ… åŒ»ç–—æ•°æ®å·¥ç¨‹æ¼”ç¤ºå®Œæˆï¼")
            return demo_result
            
        except Exception as e:
            logger.error(f"åŒ»ç–—æ•°æ®å·¥ç¨‹æ¼”ç¤ºå¤±è´¥: {e}")
            demo_result["demo_info"]["end_time"] = datetime.now().isoformat()
            demo_result["demo_info"]["status"] = "failed"
            demo_result["demo_info"]["error"] = str(e)
            
            return demo_result
    
    def generate_demo_report(self, demo_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š
        
        Args:
            demo_result: æ¼”ç¤ºç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„æ¼”ç¤ºæŠ¥å‘Š
        """
        report_lines = []
        
        # æ ‡é¢˜
        report_lines.append("=" * 60)
        report_lines.append("ğŸ¥ åŒ»ç–—æ•°æ®å·¥ç¨‹ä¸æ¨¡å‹è®­ç»ƒæ¼”ç¤ºæŠ¥å‘Š")
        report_lines.append("=" * 60)
        
        # åŸºæœ¬ä¿¡æ¯
        demo_info = demo_result.get("demo_info", {})
        report_lines.append(f"ğŸ“Š æ¼”ç¤ºçŠ¶æ€: {demo_info.get('status', 'unknown')}")
        report_lines.append(f"ğŸ“ è¾“å…¥æ–‡æœ¬é•¿åº¦: {demo_info.get('input_text_length', 0)} å­—ç¬¦")
        report_lines.append(f"ğŸ¯ ç›®æ ‡Q&Aæ•°é‡: {demo_info.get('qa_target_count', 0)}")
        report_lines.append(f"ğŸ—„ï¸ çŸ¥è¯†åº“é›†æˆ: {'æ˜¯' if demo_info.get('knowledge_base_integration') else 'å¦'}")
        report_lines.append("")
        
        # å¤„ç†æ­¥éª¤
        report_lines.append("ğŸ”„ å¤„ç†æ­¥éª¤è¯¦æƒ…:")
        report_lines.append("-" * 40)
        
        for step in demo_result.get("processing_steps", []):
            status_icon = "âœ…" if step["status"] == "completed" else "âŒ"
            report_lines.append(f"{status_icon} æ­¥éª¤{step['step_number']}: {step['step_name']}")
            report_lines.append(f"   â±ï¸ å¤„ç†æ—¶é—´: {step.get('processing_time', 0):.2f}ç§’")
            
            if step["step_name"] == "åŒ»ç–—æ•°æ®æ¸…æ´—":
                report_lines.append(f"   ğŸ“ è¾“å…¥é•¿åº¦: {step.get('input_length', 0)} â†’ è¾“å‡ºé•¿åº¦: {step.get('output_length', 0)}")
                report_lines.append(f"   ğŸ¯ è´¨é‡è¯„åˆ†: {step.get('quality_score', 0):.2f}")
                report_lines.append(f"   ğŸ·ï¸ åŒ»å­¦æœ¯è¯­: {step.get('medical_terms_extracted', 0)} ç±»")
                report_lines.append(f"   ğŸ“‘ æ–‡æœ¬æ®µè½: {step.get('segments_created', 0)} ä¸ª")
                
            elif step["step_name"] == "åŒ»ç–—ä¸“ä¸šæ ‡æ³¨":
                report_lines.append(f"   ğŸ·ï¸ ç—…ç†æ ‡æ³¨: {step.get('pathology_annotations', 0)} ä¸ª")
                report_lines.append(f"   ğŸ©º è¯Šæ–­æ ‡æ³¨: {step.get('diagnosis_annotations', 0)} ä¸ª")
                report_lines.append(f"   ğŸ”— å…³é”®å®ä½“: {step.get('key_entities', 0)} ä¸ª")
                report_lines.append(f"   ğŸ”„ å…³ç³»æŠ½å–: {step.get('relationships', 0)} ä¸ª")
                
            elif step["step_name"] == "åŒ»ç–—Q&Aæ•°æ®é›†ç”Ÿæˆ":
                report_lines.append(f"   ğŸ¯ ç›®æ ‡æ•°é‡: {step.get('target_qa_count', 0)}")
                report_lines.append(f"   âœ… å®é™…ç”Ÿæˆ: {step.get('actual_qa_count', 0)}")
                report_lines.append(f"   â­ å¹³å‡è´¨é‡: {step.get('average_quality', 0):.2f}")
                
            elif step["step_name"] == "çŸ¥è¯†åº“é›†æˆ":
                if step["status"] == "completed":
                    report_lines.append(f"   ğŸ“š ç´¢å¼•åç§°: {step.get('index_name', 'unknown')}")
                    report_lines.append(f"   ğŸ“„ æ–‡æ¡£ç´¢å¼•: {step.get('documents_indexed', 0)} ä¸ª")
                else:
                    report_lines.append(f"   âŒ é”™è¯¯ä¿¡æ¯: {step.get('error', 'unknown')}")
            
            report_lines.append("")
        
        # æœ€ç»ˆç»“æœ
        final_results = demo_result.get("final_results", {})
        report_lines.append("ğŸ“Š æœ€ç»ˆç»“æœç»Ÿè®¡:")
        report_lines.append("-" * 40)
        
        # æ•°æ®æ¸…æ´—ç»“æœ
        cleaning = final_results.get("data_cleaning", {})
        report_lines.append(f"ğŸ§¹ æ•°æ®æ¸…æ´—:")
        report_lines.append(f"   ğŸ“ æ–‡æœ¬å‹ç¼©ç‡: {(1 - cleaning.get('cleaned_length', 0) / max(cleaning.get('original_length', 1), 1)) * 100:.1f}%")
        report_lines.append(f"   ğŸ¯ æ•°æ®è´¨é‡: {cleaning.get('quality_score', 0):.2f}/1.0")
        report_lines.append(f"   ğŸ·ï¸ åŒ»å­¦æœ¯è¯­ç±»åˆ«: {len(cleaning.get('medical_terms', {}))}")
        
        # Q&Aç”Ÿæˆç»“æœ
        qa_gen = final_results.get("qa_generation", {})
        report_lines.append(f"â“ Q&Aç”Ÿæˆ:")
        report_lines.append(f"   ğŸ“ é—®ç­”å¯¹æ•°é‡: {qa_gen.get('total_qa_pairs', 0)}")
        quality_metrics = qa_gen.get("quality_metrics", {})
        report_lines.append(f"   â­ æ•´ä½“è´¨é‡: {quality_metrics.get('overall_quality', 0):.2f}")
        
        # æ€§èƒ½æŒ‡æ ‡
        performance = demo_result.get("performance_metrics", {})
        report_lines.append(f"âš¡ æ€§èƒ½æŒ‡æ ‡:")
        report_lines.append(f"   â±ï¸ æ€»å¤„ç†æ—¶é—´: {performance.get('total_processing_time', 0):.2f}ç§’")
        report_lines.append(f"   âœ… æˆåŠŸç‡: {performance.get('success_rate', 0) * 100:.1f}%")
        report_lines.append(f"   ğŸ“ˆ çŸ¥è¯†æå–æ•ˆç‡: {performance.get('knowledge_extraction_efficiency', 0):.2f} Q&Aå¯¹/åƒå­—ç¬¦")
        
        report_lines.append("")
        report_lines.append("=" * 60)
        report_lines.append("ğŸ‰ æ¼”ç¤ºæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        report_lines.append("=" * 60)
        
        return "\n".join(report_lines)